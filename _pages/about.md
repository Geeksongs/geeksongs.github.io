---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a first-year Master's student at [Columbia University](https://www.columbia.edu/), and I am honored to conduct research under the guidance of [Dr. Junfeng Yang](https://www.cs.columbia.edu/~junfeng/) at Columbia University, I focus on *AI safety* and *LLM reasoning*. At New York University, advised by [Chen Feng](https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en), I work on *Robot Learning*. At the University of Virginia with [Lehan Yang](https://bio.lehanyang.info/), I study diffusion models to *build world models*.  

My goal is to build **General-Purpose Robotics** and Grant human beings infinite lifespan. Donâ€™t be afraid â€”  **We are destined to succeed**!

My research interests lie in the intersection of **Foundation Models**,  **Robotics**, **Proactive AI Agent**, and **Neuroscience**. Additionally, I have gained valuable industry experience as a Deep Learning Algorithm Engineer Intern at both [TikTok](https://www.tiktok.com/) and [JD.com](https://www.jd.com/). In addition, I am also the author of the popular book *Learn Android Development from Zero*, and have founded multiple start-up companies.

Research Direction
======

<img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/robot.png" 
     alt="Research Direction" 
     style="height: 500px; width: auto; display: block; margin: 0 auto;" />



<!-- çº¢è‰² News æ ‡é¢˜ -->
<h2 style="color: red;">News</h2>

<ul>
   <li><strong>[2025-06-01]</strong> I am included on the 
  <a href="https://studentadmincomms.sydney.edu.au/link/id/zzzz6839191310057843Pzzzz660ce23df39ec316/page.html" target="_blank">University of Sydney Prizes and Honour Roll</a> ðŸŽ‰in University official website!</li>
  <li><strong>[2025-05-25]</strong> I have released the NeuroAurora DatasetðŸ”¥ðŸ”¥, the first Proactive AI datasets with exocentric videos!</li>
</ul>




Book
======
<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap;">
<img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/book.png" alt="Book Cover" style="height: 200px; width: auto; object-fit: contain; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /> 
  <div style="margin-left: 20px; max-width: 100%; text-align: left;">
    <h3><strong><em>Learn Android Development from Zero</em></strong></h3>
    <p style="font-size: 14px; margin-bottom: 5px;"><strong>Python Song</strong></p>
    <p style="font-size: 14px; margin-top: 0px; margin-bottom: 0px;">Mechanical Industry Press, Ranked 9th on the List of <em>Most-Read Books Among Programmers</em> in JD.com</p>
  </div>
</div>

<br>

Ongoing Projects
======
<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap; min-width: 500px;">
  <img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/captcha.jpeg" alt="VRMDiff"
    style="height: 180px; width: auto; max-width: 200px; flex-shrink: 0; margin-right: 20px; object-fit: contain;" />
  <div style="width: calc(100% - 220px); text-align: left;">
    <h3 style="margin-top: 0;"><strong>Visual-Action PAD: Visual Chain of Thought for CAPTCHA Solving via Multimodal Model Alignment</strong></h3>
    <p style="font-size: 14px; margin-bottom: 5px;">I have designed a vision-language model for reasoning to solve CAPTCHAs, achieving state-of-the-art performance and ranking Number 1 in the world. This is also the first System that can crack all kinds of Captchas full automatically with strong Generalizability</p>
  </div>
</div>


<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap; min-width: 500px;">
  <img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/robot.jpeg" alt="VRMDiff"
    style="height: 180px; width: auto; max-width: 200px; flex-shrink: 0; margin-right: 20px; object-fit: contain;" />
  <div style="width: calc(100% - 220px); text-align: left;">
    <h3 style="margin-top: 0;"><strong>Seeing from Afar: Enhancing Dexterous Hand Control with Exocentric World Models</strong></h3>
    <p style="font-size: 14px; margin-bottom: 5px;">We are using world model to enhance the capability the dexterous Hand</p>
  </div>
</div>


<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap; min-width: 500px;">
  <img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/aiagent.png" alt="VRMDiff"
    style="height: 180px; width: auto; max-width: 200px; flex-shrink: 0; margin-right: 20px; object-fit: contain;" />
  <div style="width: calc(100% - 220px); text-align: left;">
    <h3 style="margin-top: 0;" > <a href="https://geeksongs.github.io/NeuroAurora/" target="_blank"><strong>NeuroAurora: A Benchmark for Proactive Multimodal Agents with Life-Long Memory and Exocentric Perception</strong></a></h3>
    <p style="font-size: 14px; margin-bottom: 5px;">We introduce the world first multimodal dataset with exocentric video specifically designed to support Proactive AI agents.</p>
  </div>
</div>


Publication
======
<!-- VRMDiff -->
<!-- VRMDiff -->
<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap; min-width: 500px;">
  <img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/pub1.png" alt="VRMDiff"
    style="height: 180px; width: auto; max-width: 200px; flex-shrink: 0; margin-right: 20px; object-fit: contain;" />
  <div style="width: calc(100% - 220px); text-align: left;">
    <h3 style="margin-top: 0;"><strong>VRMDiff: Text-Guided Video Referring Matting Generation of Diffusion</strong></h3>
    <p style="font-size: 14px; margin-bottom: 5px;">Lehan Yang, <strong>Python Song</strong>, Tianlong Wang, Daiqing Qi, Weili Shi, Yuheng Liu, Sheng Li</p>
    <p style="font-size: 14px; margin: 0;">Submitted to ICCV, 2025 (Under Review)</p>
  </div>
</div>

<!-- NTIRE 2024 -->
<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap; min-width: 500px;">
  <img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/pub3.png" alt="NTIRE"
    style="height: 180px; width: auto; max-width: 200px; flex-shrink: 0; margin-right: 20px; object-fit: contain;" />
  <div style="width: calc(100% - 220px); text-align: left;">
    <h3 style="margin-top: 0;"><strong>NTIRE 2024 Dense and Non-Homogeneous Dehazing Challenge Report</strong></h3>
    <p style="font-size: 14px; margin: 0;">Accepted by CVPR Workshop, 2024. Cited by 24 Times</p>
  </div>
</div>

<!-- Knowledge Distillation -->
<div style="display: flex; align-items: center; justify-content: flex-start; flex-wrap: nowrap; min-width: 500px;">
  <img src="https://github.com/Geeksongs/geeksongs.github.io/raw/master/images/paper2.png" alt="KD"
    style="height: 180px; width: auto; max-width: 200px; flex-shrink: 0; margin-right: 20px; object-fit: contain;" />
  <div style="width: calc(100% - 220px); text-align: left;">
    <h3 style="margin-top: 0;"><strong>Rethinking the Knowledge Distillation From the Perspective of Model Calibration</strong></h3>
    <p style="font-size: 14px; margin-bottom: 5px;">Lehan Yang, <strong>Python Song</strong></p>
    <p style="font-size: 14px; margin: 0;">Cited by 3 Times, Reported by <strong>Medium.com</strong></p>
  </div>
</div>



<br>


Honor 
======
- Highest Honor Graduate Student with **First-Class Honour** at the University of Sydney (**Top 1%**)
- National High School Physics Olympiad: **National First-Prize** (**Top 0.01%**)
- CCF Big Data and Computing Intelligence Contest: **Top 2%**
- **GitHub:** [https://github.com/geeksongs](https://github.com/geeksongs) with **130+ Star**
- **CSDN:** [https://blog.csdn.net/Geeksongs](https://blog.csdn.net/Geeksongs) with **8800+ Fans** (**The Biggest IT Blog community in Asian**)






